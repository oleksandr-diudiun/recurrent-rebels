{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "4634f49e-4859-4015-b368-990d6ce11de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_len  sepal_wid  petal_len  petal_wid  class\n",
      "0          5.7        2.8        4.1        1.3      1\n",
      "1          7.3        2.9        6.3        1.8      2\n",
      "2          5.0        3.3        1.4        0.2      0\n",
      "3          6.9        3.1        4.9        1.5      1\n",
      "4          5.6        3.0        4.5        1.5      1\n",
      "..         ...        ...        ...        ...    ...\n",
      "145        5.2        3.5        1.5        0.2      0\n",
      "146        5.0        3.5        1.3        0.3      0\n",
      "147        5.0        3.6        1.4        0.2      0\n",
      "148        7.7        2.8        6.7        2.0      2\n",
      "149        5.2        4.1        1.5        0.1      0\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# since this is a bunch, create a dataframe\n",
    "\n",
    "iris_df=pd.DataFrame(iris.data)\n",
    "iris_df['class']=iris.target\n",
    "iris_df.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']\n",
    "iris_df.dropna(how=\"all\", inplace=True) # remove any empty lines\n",
    "iris = iris_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(iris)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "e8755eb3-ec1c-4166-966f-51ab89200dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    numberOfClasses = 0\n",
    "    numberOfFeatures = 0\n",
    "    numberOfHiddenLayerUnits = 0\n",
    "    X = None\n",
    "    Y = None\n",
    "    X_forTraining = None\n",
    "    X_forTesting = None\n",
    "    Y_forTraining = None\n",
    "    Y_forTesting = None\n",
    "    Y_train_encoded = None\n",
    "    Y_test_encoded = None\n",
    "    W1 = None\n",
    "    b1 = None\n",
    "    W2 = None\n",
    "    b2 = None\n",
    "    splitRange = 75\n",
    "    \n",
    "    # One-hot encode the labels for categorical cross-entropy\n",
    "    def one_hot_encode(self, labels, num_classes):\n",
    "        return np.eye(num_classes)[labels]\n",
    "        \n",
    "    def prepareInputData(self, inputDataFrame: pd.DataFrame, numberOfClasses: int, numberOfFeatures: int, numberOfHiddenLayerUnits: int, splitRange):\n",
    "        self.numberOfClasses = numberOfClasses\n",
    "        self.numberOfFeatures = numberOfFeatures\n",
    "        self.numberOfHiddenLayerUnits = numberOfHiddenLayerUnits\n",
    "        self.splitRange = splitRange\n",
    "        self.X = inputDataFrame.iloc[:, 0:numberOfFeatures]\n",
    "        self.Y = inputDataFrame.iloc[:, -1]\n",
    "        \n",
    "        \n",
    "        self.X_forTraining, self.X_forTesting = self.X.iloc[:self.splitRange], self.X.iloc[self.splitRange:]\n",
    "        self.Y_forTraining,self.Y_forTesting = self.Y.iloc[:self.splitRange], self.Y.iloc[self.splitRange:]\n",
    "        \n",
    "        print(self.Y_forTraining)\n",
    "        print(self.Y_forTesting)\n",
    "\n",
    "        self.Y_train_encoded = self.one_hot_encode(self.Y_forTraining, self.numberOfClasses)\n",
    "        self.Y_test_encoded = self.one_hot_encode(self.Y_forTesting, self.numberOfClasses)\n",
    "    \n",
    "    def initializeStartParameters(self):\n",
    "        np.random.seed(42)\n",
    "        self.W1 = np.random.randn(self.numberOfFeatures, self.numberOfHiddenLayerUnits)\n",
    "        self.b1 = np.zeros((1, self.numberOfHiddenLayerUnits))\n",
    "        self.W2 = np.random.randn(self.numberOfHiddenLayerUnits, self.numberOfClasses)\n",
    "        self.b2 = np.zeros((1, self.numberOfClasses))\n",
    "    \n",
    "    def relu(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "\n",
    "    def relu_derivative(self,Z):\n",
    "        return Z > 0\n",
    "\n",
    "    def softmax(self,Z):\n",
    "        Z = Z.to_numpy()\n",
    "        expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "        return expZ / np.sum(expZ, axis=1, keepdims=True)\n",
    "\n",
    "    def compute_loss(self,Y, Y_hat):\n",
    "        m = Y.shape[0]\n",
    "        return -np.sum(Y * np.log(Y_hat + 1e-9)) / m\n",
    "    \n",
    "    def forwardPropagation(self, X):\n",
    "        Z1 = X.dot(self.W1) + self.b1\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = A1.dot(self.W2) + self.b2\n",
    "        A2 = self.softmax(Z2)\n",
    "        return {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n",
    "    \n",
    "    def backwardPropagation(self, X, Y, cache):\n",
    "        m = X.shape[0]\n",
    "\n",
    "        dZ2 = cache[\"A2\"] - Y\n",
    "        dW2 = (1 / m) * np.dot(cache[\"A1\"].T, dZ2)\n",
    "        \n",
    "        db2 = (1 / m) * np.sum(dZ2, axis=0, keepdims=True)\n",
    "        dZ1 = np.dot(dZ2, self.W2.T) * self.relu_derivative(cache[\"Z1\"])\n",
    "\n",
    "        dW1 = (1 / m) * np.dot(X.T, dZ1)\n",
    "        \n",
    "        db1 = (1 / m) * np.sum(dZ1.to_numpy(), axis=0, keepdims=True)\n",
    "\n",
    "        return {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "\n",
    "    def updateParameters(self, grads, learningRate):\n",
    "        self.W1 -= learningRate * grads[\"dW1\"]\n",
    "        self.b1 -= learningRate * grads[\"db1\"]\n",
    "        self.W2 -= learningRate * grads[\"dW2\"]\n",
    "        self.b2 -= learningRate * grads[\"db2\"]\n",
    "        return params\n",
    "\n",
    "    def evaluate( self):\n",
    "        # Perform forward propagation to get predictions\n",
    "        cache = self.forwardPropagation(self.X_forTesting)\n",
    "        predictions = np.argmax(cache[\"A2\"], axis=1)  # Choose the class with the highest probability\n",
    "\n",
    "        print(predictions)\n",
    "        print(self.Y_forTesting.to_numpy())\n",
    "    \n",
    "        # Calculate accuracy\n",
    "        accuracy = np.mean(predictions == self.Y_forTesting) * 100  # Compare predictions to true labels and compute percentage\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "557b613c-1363-4392-a038-845ae0ace12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      2\n",
      "2      0\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "135    0\n",
      "136    2\n",
      "137    1\n",
      "138    0\n",
      "139    1\n",
      "Name: class, Length: 140, dtype: int64\n",
      "140    0\n",
      "141    2\n",
      "142    0\n",
      "143    1\n",
      "144    2\n",
      "145    0\n",
      "146    0\n",
      "147    0\n",
      "148    2\n",
      "149    0\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Iris = Model()\n",
    "Iris.prepareInputData(iris, 3, 4, 5, 140)\n",
    "Iris.initializeStartParameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "2b14f882-9e6c-404b-946b-225bd47926d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training loss: 7.3519, Test loss: 10.2846\n",
      "Epoch 100, Training loss: 0.6116, Test loss: 0.4361\n",
      "Epoch 200, Training loss: 0.5246, Test loss: 0.3252\n",
      "Epoch 300, Training loss: 0.4684, Test loss: 0.2696\n",
      "Epoch 400, Training loss: 0.4092, Test loss: 0.2265\n",
      "Epoch 500, Training loss: 0.3581, Test loss: 0.1898\n",
      "Epoch 600, Training loss: 0.3139, Test loss: 0.1577\n",
      "Epoch 700, Training loss: 0.2767, Test loss: 0.1304\n",
      "Epoch 800, Training loss: 0.2459, Test loss: 0.1082\n",
      "Epoch 900, Training loss: 0.2206, Test loss: 0.0905\n",
      "[0 2 0 1 2 0 0 0 2 0]\n",
      "[0 2 0 1 2 0 0 0 2 0]\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate=0.01\n",
    "epochs=1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass on training data\n",
    "    train_cache = Iris.forwardPropagation(Iris.X_forTraining)\n",
    "    \n",
    "    loss = Iris.compute_loss(Iris.Y_train_encoded, train_cache[\"A2\"])\n",
    "    \n",
    "    # Backward pass (compute gradients)\n",
    "    grads = Iris.backwardPropagation(Iris.X_forTraining, Iris.Y_train_encoded, train_cache)\n",
    "    \n",
    "    # Update parameters\n",
    "    params = Iris.updateParameters(grads, learning_rate)\n",
    "    \n",
    "    # Print the loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        test_cache = Iris.forwardPropagation(Iris.X_forTesting)\n",
    "        test_loss = Iris.compute_loss(Iris.Y_test_encoded, test_cache[\"A2\"])\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Training loss: {loss:.4f}, Test loss: {test_loss:.4f}\")\n",
    "accuracy = Iris.evaluate()\n",
    "\n",
    "print(f\"Accuracy: {accuracy :.2f}%\")\n",
    "\n",
    "Iris.initializeStartParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811540c-2cf5-4a92-bdd5-5e9413c014fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f58e32-e688-4def-8502-ca42a23a08fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
